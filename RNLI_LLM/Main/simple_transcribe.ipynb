{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b51a29fa",
   "metadata": {},
   "source": [
    "# Simple Transcribe\n",
    "Transcribe an audio file using Whisper base model (English only)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a89a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install openai-whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e64f7cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from RNLI_LLM.Transcript import transcribe_audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c74fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "input_audio = '/dbfs/FileStore/input.wav'  # Update path as needed for Databricks\n",
    "output_txt = '/dbfs/FileStore/output.txt'\n",
    "transcript = transcribe_audio(\n",
    "    input_audio,\n",
    "    output_txt=output_txt,\n",
    "    model_size='base',\n",
    "    language='en'\n",
    ")\n",
    "print(transcript)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
