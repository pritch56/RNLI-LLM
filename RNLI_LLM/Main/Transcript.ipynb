{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a7ea076",
   "metadata": {},
   "source": [
    "# Transcript Utilities\n",
    "This notebook provides functions for transcribing audio using OpenAI Whisper, with optional SRT/VTT output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4f0343",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages (uncomment if needed)\n",
    "# %pip install openai-whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6eaeefd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import argparse\n",
    "\n",
    "# Try to import Whisper for speech-to-text\n",
    "try:\n",
    "    import whisper\n",
    "except ImportError:\n",
    "    print(\"The 'whisper' package is not installed. Please see the instructions below.\")\n",
    "    sys.exit(1)\n",
    "\n",
    "# Optional: For SRT/VTT subtitle output\n",
    "try:\n",
    "    from whisper.utils import write_srt, write_vtt\n",
    "except ImportError:\n",
    "    write_srt = None\n",
    "    write_vtt = None\n",
    "\n",
    "def transcribe_audio(\n",
    "    input_audio,\n",
    "    output_txt=None,\n",
    "    output_srt=None,\n",
    "    output_vtt=None,\n",
    "    model_size='large',\n",
    "    language=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Transcribe audio using OpenAI Whisper and save results in text, SRT, and VTT formats.\n",
    "    Args:\n",
    "        input_audio (str): Path to the input audio file (any format supported by Whisper)\n",
    "        output_txt (str): Path to save the plain text transcript\n",
    "        output_srt (str, optional): Path to save SRT subtitles\n",
    "        output_vtt (str, optional): Path to save VTT subtitles\n",
    "        model_size (str): Whisper model size (tiny, base, small, medium, large)\n",
    "        language (str, optional): Language code (e.g., 'en') or None for auto-detect\n",
    "    \"\"\"\n",
    "    model = whisper.load_model(model_size)\n",
    "    print(f\"Loaded Whisper model: {model_size}\")\n",
    "    try:\n",
    "        result = model.transcribe(input_audio, language=language, verbose=True, task='transcribe')\n",
    "    except Exception as e:\n",
    "        print(\"Audio loading failed. Make sure your input file is a 16-bit, 16kHz, mono WAV file.\")\n",
    "        print(f\"Error: {e}\")\n",
    "        raise\n",
    "    transcript = result['text'].strip()\n",
    "\n",
    "    # Write plain text output if output_txt is provided\n",
    "    if output_txt:\n",
    "        with open(output_txt, 'w', encoding='utf-8') as f:\n",
    "            f.write(transcript + '\\n')\n",
    "        print(f\"Transcription saved to {output_txt}\")\n",
    "\n",
    "    # Write SRT subtitles if requested and supported\n",
    "    if output_srt and write_srt:\n",
    "        with open(output_srt, 'w', encoding='utf-8') as f:\n",
    "            write_srt(result['segments'], file=f)\n",
    "        print(f\"SRT subtitles saved to {output_srt}\")\n",
    "    # Write VTT subtitles if requested and supported\n",
    "    if output_vtt and write_vtt:\n",
    "        with open(output_vtt, 'w', encoding='utf-8') as f:\n",
    "            write_vtt(result['segments'], file=f)\n",
    "        print(f\"VTT subtitles saved to {output_vtt}\")\n",
    "\n",
    "    # Print detected language\n",
    "    print(f\"Detected language: {result['language']}\")\n",
    "    return transcript"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
